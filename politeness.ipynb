{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb2be76",
   "metadata": {},
   "source": [
    "# Finding Politeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc625f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None, 'display.max_rows', None, )\n",
    "\n",
    "dataset_dir = \"../../final_dataset/\"\n",
    "\n",
    "#SUBSETS = \"train dev test\".split()\n",
    "SUBSETS = [\"train\"]\n",
    "\n",
    "\n",
    "datasets = collections.defaultdict(list)\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    for filename in glob.glob(dataset_dir + subset + \"/*\"):\n",
    "        with open(filename, 'r') as f:\n",
    "            datasets[subset].append(json.load(f))\n",
    "            \n",
    "all_pairs = sum(datasets.values(), [])\n",
    "\n",
    "def total_and_average_len(list_of_lists):\n",
    "    big_list = sum(list_of_lists, [])\n",
    "    return len(big_list), len(big_list)/len(list_of_lists)\n",
    "\n",
    "def count_dataset(pairs, subset):\n",
    "    # TODO: Add double-annotated and adjudicated\n",
    "    review_total, review_average = total_and_average_len([pair[\"review_sentences\"] for pair in pairs])\n",
    "    rebuttal_total, rebuttal_average = total_and_average_len([pair[\"rebuttal_sentences\"] for pair in pairs])\n",
    "    return {\n",
    "        \"subset\":subset,\n",
    "        \"pairs\": len(pairs),\n",
    "        \"forums\": len(set(pair[\"metadata\"][\"forum_id\"] for pair in pairs)),\n",
    "        \"adjudicated\": len([pair for pair in pairs if pair[\"metadata\"][\"annotator\"] == \"anno0\"]),\n",
    "        \"review_sentences\": review_total,\n",
    "        \"rebuttal_sentences\": rebuttal_total,\n",
    "        \"review_avg_sentences\": review_average,\n",
    "        \"rebuttal_avg_sentences\": rebuttal_average,\n",
    "        \n",
    "    }\n",
    "# Distribution of examples over sets\n",
    "df_dicts = [count_dataset(pairs, subset) for subset, pairs in datasets.items()]\n",
    "df = pd.DataFrame.from_dict(df_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95412f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'politeness_markers_==Please==': [],\n",
       " 'politeness_markers_==Please_start==': [],\n",
       " 'politeness_markers_==HASHEDGE==': [],\n",
       " 'politeness_markers_==Indirect_(btw)==': [],\n",
       " 'politeness_markers_==Hedges==': [],\n",
       " 'politeness_markers_==Factuality==': [],\n",
       " 'politeness_markers_==Deference==': [],\n",
       " 'politeness_markers_==Gratitude==': [],\n",
       " 'politeness_markers_==Apologizing==': [],\n",
       " 'politeness_markers_==1st_person_pl.==': [[('we', 1, 19)]],\n",
       " 'politeness_markers_==1st_person==': [[('i', 1, 10)]],\n",
       " 'politeness_markers_==1st_person_start==': [],\n",
       " 'politeness_markers_==2nd_person==': [],\n",
       " 'politeness_markers_==2nd_person_start==': [],\n",
       " 'politeness_markers_==Indirect_(greeting)==': [],\n",
       " 'politeness_markers_==Direct_question==': [],\n",
       " 'politeness_markers_==Direct_start==': [],\n",
       " 'politeness_markers_==HASPOSITIVE==': [],\n",
       " 'politeness_markers_==HASNEGATIVE==': [[('problem', 1, 7)],\n",
       "  [('problem', 1, 25)],\n",
       "  [('problem', 1, 27)]],\n",
       " 'politeness_markers_==SUBJUNCTIVE==': [],\n",
       " 'politeness_markers_==INDICATIVE==': []}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.convokit_politeness import get_convokit_politeness_labels\n",
    "\n",
    "pair = all_pairs[1]\n",
    "\n",
    "all_sentences = {\n",
    "    'metadata': {'review_id': 'xyz'},\n",
    "    'review_sentences': [],\n",
    "    'rebuttal_sentences': []\n",
    "}\n",
    "\n",
    "for pair in all_pairs:\n",
    "    all_sentences['review_sentences'] += pair['review_sentences']\n",
    "    all_sentences['rebuttal_sentences'] += pair['rebuttal_sentences']\n",
    "\n",
    "get_convokit_politeness_labels(pair)['meta.politeness_markers'][0]\n",
    "# pair_df = get_convokit_politeness_labels(all_sentences)\n",
    "# pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49258cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4990231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>text</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>asp</th>\n",
       "      <th>pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1ez1LvJcB</td>\n",
       "      <td>0</td>\n",
       "      <td>This paper presents a method for adapting a model that has been trained to perform one task, so that it can perform a new task (potentially without using any new training data at all—i.e., zero-shot learning).</td>\n",
       "      <td>arg_structuring</td>\n",
       "      <td>arg-structuring_summary</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1ez1LvJcB</td>\n",
       "      <td>1</td>\n",
       "      <td>In some ways the presented work is a form of meta-learning or *meta-mapping* as the authors refer to it.</td>\n",
       "      <td>arg_structuring</td>\n",
       "      <td>arg-structuring_summary</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1ez1LvJcB</td>\n",
       "      <td>2</td>\n",
       "      <td>The premise of the paper is very interesting and the overall problem is definitely of high interest and high potential impact.</td>\n",
       "      <td>arg_evaluative</td>\n",
       "      <td>none</td>\n",
       "      <td>asp_motivation-impact</td>\n",
       "      <td>pol_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1ez1LvJcB</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe that the presentation of the proposed method can be significantly improved.</td>\n",
       "      <td>arg_request</td>\n",
       "      <td>arg-request_edit</td>\n",
       "      <td>asp_clarity</td>\n",
       "      <td>pol_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1ez1LvJcB</td>\n",
       "      <td>4</td>\n",
       "      <td>The method description was a bit confusing and unclear to me.</td>\n",
       "      <td>arg_evaluative</td>\n",
       "      <td>none</td>\n",
       "      <td>asp_clarity</td>\n",
       "      <td>pol_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id  sentence_index  \\\n",
       "0  B1ez1LvJcB               0   \n",
       "1  B1ez1LvJcB               1   \n",
       "2  B1ez1LvJcB               2   \n",
       "3  B1ez1LvJcB               3   \n",
       "4  B1ez1LvJcB               4   \n",
       "\n",
       "                                                                                                                                                                                                                text  \\\n",
       "0  This paper presents a method for adapting a model that has been trained to perform one task, so that it can perform a new task (potentially without using any new training data at all—i.e., zero-shot learning).   \n",
       "1                                                                                                           In some ways the presented work is a form of meta-learning or *meta-mapping* as the authors refer to it.   \n",
       "2                                                                                     The premise of the paper is very interesting and the overall problem is definitely of high interest and high potential impact.   \n",
       "3                                                                                                                              I believe that the presentation of the proposed method can be significantly improved.   \n",
       "4                                                                                                                                                      The method description was a bit confusing and unclear to me.   \n",
       "\n",
       "            coarse                     fine                    asp  \\\n",
       "0  arg_structuring  arg-structuring_summary                   none   \n",
       "1  arg_structuring  arg-structuring_summary                   none   \n",
       "2   arg_evaluative                     none  asp_motivation-impact   \n",
       "3      arg_request         arg-request_edit            asp_clarity   \n",
       "4   arg_evaluative                     none            asp_clarity   \n",
       "\n",
       "            pol  \n",
       "0          none  \n",
       "1          none  \n",
       "2  pol_positive  \n",
       "3  pol_negative  \n",
       "4  pol_negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.json_normalize(all_pairs[1], record_path=['review_sentences'])\n",
    "rs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = all_pairs[9]\n",
    "\n",
    "df = get_convokit_politeness_labels(pair)\n",
    "\n",
    "# len(all_pairs[1]['review_sentences'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
